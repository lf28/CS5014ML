{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a705a7",
   "metadata": {},
   "source": [
    "# CS5014 Machine Learning \n",
    "##### Credits: 50% of the coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26dde6",
   "metadata": {},
   "source": [
    "## Aims\n",
    "\n",
    "\n",
    "The objectives of this assignment are:\n",
    "\n",
    "* deepen your understanding of linear regression and logistic regression\n",
    "* gain experience in implementing learning algorithms \n",
    "* gain experience in evaluating machine learning algorithms\n",
    "* gain experience in hyper-parameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662dc6a",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "You are **only allowed** to use the following imported packages for this practical. No off-the-shelf machine learning packages such as _scikit-learn_ are allowed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931f3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use jupyter-lab, switch to %matplotlib inline instead\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "%config Completer.use_jedi = False\n",
    "import matplotlib.pyplot as plt\n",
    "import autograd.numpy as np  # Thinly-wrapped numpy\n",
    "from autograd import grad    # The only autograd function you may ever need\n",
    "import autograd.numpy.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a5d9e-e308-42c9-8dc8-d5d42c4055fa",
   "metadata": {},
   "source": [
    "The following method computes the gradient of a given function $f$ at an input location `initial`. Note that the finite difference method suffers from truncating and rounding errors and can be slow for large-scale machine learning models. It should never be directly used in a gradient descent algorithm. But it can be very useful to check your gradient derivation and implementation. You should always check your gradients before using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedfaf21-f585-47e4-a083-df8d9bd467ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_difference_gradient(f, initial, eps=1e-6):\n",
    "    initial = np.array(initial, dtype=float)\n",
    "    n = len(initial)\n",
    "    output = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        ei = np.zeros(n)\n",
    "        ei[i] = 1\n",
    "        f1 = f(initial + eps * ei)\n",
    "        f2 = f(initial - eps * ei)\n",
    "        output[i] = (f1-f2)/(2*eps)\n",
    "    output = output.reshape(n,1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211324e",
   "metadata": {},
   "source": [
    "## Question 1 (Logistic regression)\n",
    "\n",
    "In this question, we are going to implement a logistic regression model to do binary classification on a simulated dataset. The dataset's input feature are four-dimensional vectors $\\mathbf{x}^{(i)} \\in \\mathbb{R}^4$ and as expected the targets are binary, *i.e.* $y^{(i)} \\in \\{0, 1\\}$. \n",
    "\n",
    "\n",
    "The dataset $\\{\\mathbf{x}^{(i)}, y^{(i)}\\}$ is imported below for you:\n",
    "* ``dataset1``: 2000 observations and each input $\\mathbf{x}$ has 4 features \n",
    "* and the last column is the target ${y}^{(i)}$\n",
    "* the dataset is then split into training and testing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34706afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset1\n",
    "dataset1_df = pd.read_csv('./datasets/dataset1.csv', header=0)\n",
    "dataset1 = np.array(dataset1_df)\n",
    "d1X, d1Y = dataset1[:, 0:4], dataset1[:, -1]\n",
    "# split the data into training and testing \n",
    "# the training dataset has the first 1500 observation; \n",
    "# in practice, you should randomly shuffle before the split\n",
    "d1_xtrain, d1_ytrain = d1X[0:1500, :], d1Y[0:1500]\n",
    "# the testing dataset has the last 500\n",
    "d1_xtest, d1_ytest = d1X[1500:, :], d1Y[1500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3b086",
   "metadata": {},
   "source": [
    "As suggested in the lecture, it is convenient to introduce dummy variables of ones to avoid learning the bias separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87aa88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_xtrain_dummy = np.column_stack((np.ones(d1_xtrain.shape[0]), d1_xtrain))\n",
    "d1_xtest_dummy = np.column_stack((np.ones(d1_xtest.shape[0]), d1_xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270ebbf",
   "metadata": {},
   "source": [
    "### Task 1.1 Implementation of logistic regression\n",
    "\n",
    "Your task here is to implement a gradient descent based algorithm to train a logistic regression model. For this task, you cannot use `autograd`'s auto-differentiation method (*i.e.* the imported `grad` method). You will be guided to finish the task step by step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c28469",
   "metadata": {},
   "source": [
    "First, implement the `sigmoid` function:\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d77df7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # hint: use np.exp(-z)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2670fb",
   "metadata": {},
   "source": [
    "Second, implement the cross-entropy loss and its gradient. You may want to refer to the lecture slides for the details. Recall the binary **C**ross **E**ntropy (CE) _loss_ is \n",
    "\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w})=  \\frac{1}{n}\\sum_{i=1}^n -{y^{(i)}} \\ln \\sigma^{(i)}- (1- y^{(i)}) \\ln (1-\\sigma^{(i)})\n",
    "$$\n",
    "\n",
    "where $\\sigma^{(i)} =\\sigma(\\mathbf{w}^\\top\\mathbf{x}^{(i)} + b).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da95f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(w, X, y):\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8d9bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_ce_loss(w, X, y):\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafe409",
   "metadata": {},
   "source": [
    "Now, implement the gradient descent algorithm below. Before that, you should consider testing our gradient method before using it in the training algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f29df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_train(X, y, lr, tol= 1e-5, maxIters= 2000):\n",
    "    n, d = X.shape \n",
    "    # initialise w0\n",
    "    w0 = np.zeros(d)\n",
    "    l0 = cross_entropy_loss(w0, X, y)\n",
    "    losses = [l0]\n",
    "    # loop until converge\n",
    "    for i in range(maxIters):\n",
    "        ## Implement gradient descent here\n",
    "        w0 = w0\n",
    "        # Check convergence here \n",
    "        # if True:\n",
    "        #    break\n",
    "    return w0, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4e01f5",
   "metadata": {},
   "source": [
    "After you finish implementing all the above methods, use your learning algorithm to train a logistic regression model on the training dataset and answer the following questions:\n",
    "\n",
    "* plot the learning curve\n",
    "* report the learnt parameter with learning rate 0.1, `tol=1e-5` and `maxIters=2000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a1c3bd-ce1c-4121-a606-523ef126e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run your algorithm and report your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba462991",
   "metadata": {},
   "source": [
    "### Task 1.2 Testing performance\n",
    "\n",
    "Implement a prediction method that takes as input the features together with the learnt parameter and outputs the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "988713af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression(w, X = d1_xtest_dummy):\n",
    "    n, d = X.shape \n",
    "    ## fill the rest of the method\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a106d1",
   "metadata": {},
   "source": [
    "Report the test performance on the unseen test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9260650-1fdf-403b-8b45-8af6793f0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run your algorithm and report your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5eeddc",
   "metadata": {},
   "source": [
    "### Task 1.3 Regularisation\n",
    "\n",
    "In this sub-task, you are going to apply $L_2$ regularisation to the logistic regression model. The regularised loss is\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w})=  \\frac{1}{n}\\sum_{i=1}^n -{y^{(i)}} \\ln \\sigma^{(i)}- (1- y^{(i)}) \\ln (1-\\sigma^{(i)}) + \\frac{\\lambda}{2} \\mathbf{w}^\\top\\mathbf{w}\n",
    "$$\n",
    "\n",
    "* where $\\lambda >0$ is the regularisation hyperparameter\n",
    "\n",
    "* note that we do not usually apply penalty on the bias parameter $b$\n",
    "\n",
    "Implement the following method that fits a regularised logistic regression model with a given $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9362f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_reg_train(X, y, lr, lam = 1.0, tol= 1e-5, maxIters= 2000):\n",
    "    n, d = X.shape \n",
    "    # initialise w0\n",
    "    w0 = np.zeros(d)\n",
    "    l0 = cross_entropy_loss(w0, X, y)\n",
    "    losses = [l0]\n",
    "    # loop until converge\n",
    "    for i in range(maxIters):\n",
    "        w0 = w0\n",
    "        \n",
    "    return w0, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fe2830",
   "metadata": {},
   "source": [
    "Complete and report the following two results\n",
    "* report the training loss and learnt parameter by setting $\\lambda=0.01$\n",
    "* report the testing performance for the regularised logistic regression model with $\\lambda=0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034441f1-227d-4c3a-825e-7aea11c78769",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run your algorithm and report your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f7c67c",
   "metadata": {},
   "source": [
    "### Task 1.4 Stochastic gradient descent \n",
    "\n",
    "\n",
    "Implement a stochastic gradient descent algorithm with a mini-batch size of 1. You should consider shuffling the training dataset to improve the convergence speed. \n",
    "\n",
    "It is a good idea to implement a decaying learning rate. One possible choice is \n",
    "$$\\gamma_t = \\frac{\\gamma_0}{1 + \\tau \\gamma_0 t}$$\n",
    "* where $\\gamma_0 >0$ is the initial learning rate,\n",
    "* and $\\tau \\geq 0$ is a tuning parameter, *e.g.* $\\tau = 0.1$\n",
    "\n",
    "After implementing the algorithm, use it to train the logistic regression model. Compare the performance with the batch learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b73e1f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_reg_sgd_train(X, y, gamma0 = 1.0, tau=0.1, tol= 1e-4, maxIters= 100):\n",
    "    n, d = X.shape \n",
    "    # initialise w0\n",
    "    w0 = np.zeros(d)\n",
    "    losses = []\n",
    "    # loop until converge\n",
    "        # for each observation (x^i, y^i) in (X, Y)\n",
    "            # compute gradient and apply gradient descent\n",
    "    \n",
    "    return w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "474b1f80-b884-4a7b-b03e-a782d326a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run your algorithm and report your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb60af2",
   "metadata": {},
   "source": [
    "## Question 2 (Fixed basis expansion)\n",
    "\n",
    "\n",
    "\n",
    "In this question, we are going to implement a fixed basis expansion regression model. The dataset for this question has a univariate feature $\\mathbf{x}^{(i)} \\in \\mathbb{R}$ and as expected the target $y^{(i)} \\in \\mathbb{R}$ is real valued. \n",
    "\n",
    "\n",
    "The dataset is imported below for you:\n",
    "* ``dataset2``: 1000 observations and each input ${x}^{(i)}$ is a scalar \n",
    "* and the last column is the target ${y}^{(i)}$\n",
    "* the dataset is then split into training and testing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd11514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset2\n",
    "dataset2_df = pd.read_csv('./datasets/dataset2.csv', header=0)\n",
    "dataset2 = np.array(dataset2_df)\n",
    "d2X, d2Y = dataset2[:, 0], dataset2[:, -1]\n",
    "# split the data into training and testing \n",
    "# the training dataset has the first 800 observation; \n",
    "# in practice, you should randomly shuffle before the split\n",
    "d2_xtrain, d2_ytrain = d2X[0:800], d2Y[0:800]\n",
    "# # the testing dataset has the last 500\n",
    "d2_xtest, d2_ytest = d2X[800:], d2Y[800:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f9bc20",
   "metadata": {},
   "source": [
    "The data is plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de5eaa32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(d2_xtrain, d2_ytrain,  c =\"blue\", s=1.5)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c80c5",
   "metadata": {},
   "source": [
    "### Task 2.1 Basis function\n",
    "\n",
    "Implement the radian-basis-function (rbf), \n",
    "\n",
    "$$\\phi(x; \\mu, s) = \\exp\\left \\{- \\frac{(x-\\mu)^2}{2s} \\right \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6a7e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_rbf(x, mu, s):\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19607083",
   "metadata": {},
   "source": [
    "### Task 2.2 Fixed basis expansion regression\n",
    "\n",
    "Implement the fixed basis expansion regression model. Specifically, you should \n",
    "* first apply $K$ fixed basis expansion on the input $\\{x^{(i)}\\}$ to form the expanded design matrix $\\mathbf{\\Phi}$\n",
    "* then fit a regression model by a non-iterative algorithm (*i.e.* the normal equation method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51f5ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_basis_rbf_reg(X, y, mus, s):\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f6341",
   "metadata": {},
   "source": [
    "Implement a prediction method `predict_rbf_reg`, that outputs the prediction $\\hat{y}$ given input $x_{test}$. Note that the method should be able to predict outputs for multiple test inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f382887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rbf_reg(X, w, mus, s):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c9607f-40a9-4217-96e0-21283807dfd1",
   "metadata": {},
   "source": [
    "Fit a fixed basis expansion regression model with $K=50$ fixed basis functions. The expansion locations $\\mu$s should be within $x$'s range. And it is up to you how to choose them (*e.g.* they can be evenly placed within the range).\n",
    "\n",
    "* try different settings (*e.g.* with different expansion location and scale $s$ choices)\n",
    "* plot the fitted function (together with the training data) of your choice \n",
    "* and report the test error on your chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e2b1a86-c2fa-4096-97af-0d43906a16b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run your algorithm and report your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567fcac5",
   "metadata": {},
   "source": [
    "### Task 2.3 Other basis function\n",
    "\n",
    "\n",
    "Implement another basis function of your choice and fit the regression model. Plot the fitted result below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d08f8",
   "metadata": {},
   "source": [
    "### Task 2.4 Advanced task (extension*)\n",
    "\n",
    "We assume the noise scale is a constant for an ordinary linear regression model. However, the noise scale for this dataset is not homogenous: it increases as $x$ gets larger. This is known as heteroscedasticity. Fit a fixed basis regression model that can also learn the adapting noise scale. You are allowed to use auto-differentiation for this question. Explain your model and report your findings in appropriate formats such as plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b10cb5",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Hand in via MMS: the completed jupyter notebook. Your notebook should be reproducible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4422044c",
   "metadata": {},
   "source": [
    "## Marking\n",
    "Your submission will be marked as a whole. \n",
    "\n",
    "* to get a grade above 7, you are expected to finish at least Task 1.1-1.2 to a good standard\n",
    "* to get a grade above 10 and up to 13, you are expected to complete Task 1.1-1.4 to a good standard\n",
    "* to get a grade above 13 and up to 17, you are expected to complete all tasks except 2.3 and 2.4 to a good standard\n",
    "* to achieve a grade of 17-18, you are expected to finish all tasks except Task 2.4 flawlessly \n",
    "* to get 18+, you are expected to attempt all questions flawlessly\n",
    "\n",
    "\n",
    "Marking is according to the standard mark descriptors published in the Student Handbook at:\n",
    "\n",
    "https://info.cs.st-andrews.ac.uk/student-handbook/learning-teaching/feedback.html#GeneralMarkDescriptors\n",
    "\n",
    "\n",
    "You must reference any external sources used. Guidelines for good academic practice are outlined in the student handbook at https://info.cs.st-andrews.ac.uk/student-handbook/academic/gap.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a35de-1c67-476e-bac3-72b14904619d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
